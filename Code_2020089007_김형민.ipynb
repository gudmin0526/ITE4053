{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b99b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"Epochs:\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4150e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. 전처리\n",
    "# -------------------------------\n",
    "root_dir = os.path.expanduser(\"./archive/chest_xray\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # 흑백(1채널)로 변환\n",
    "    transforms.Resize((128, 128)),                # 128 by 128 크기로 변환\n",
    "    transforms.ToTensor()                         # 이미지를 PyTorch Tensor로 변환\n",
    "])\n",
    "input_dim = 128 * 128  # 모델의 입력 차원\n",
    "\n",
    "# train/val/test dataset 구성\n",
    "trainval_ds = datasets.ImageFolder(os.path.join(root_dir, 'train'), transform=transform)  # train+val\n",
    "test_ds = datasets.ImageFolder(os.path.join(root_dir, 'test'),  transform=transform)      # test\n",
    "\n",
    "# train/val 분할\n",
    "train_size = int(0.8 * len(trainval_ds))  # train set의 사이즈\n",
    "val_size = len(trainval_ds) - train_size  # val set의 사이즈\n",
    "train_ds, val_ds = random_split(trainval_ds, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "print(\"train:\", train_size, \"val:\", val_size, \"test:\", len(test_ds))\n",
    "\n",
    "# DataLoader 구성 (batch_size=32, iteration마다 32개 이미지 처리)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)  # shuffle: 과적합 방지 및 일반화 성능 향상 \n",
    "val_loader = DataLoader(val_ds, batch_size=32)  \n",
    "test_loader = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb628910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2-1. Logistic 모델 정의\n",
    "# -------------------------------\n",
    "class LogisticModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # binary classficaiton\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))  # sigmoid 함수로 확률 출력 (0 ~ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ad2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2-2. DeepNN 모델 정의\n",
    "# -------------------------------\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022bb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3-1. 학습 진행하는 함수 (학습)\n",
    "# -------------------------------\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()  # 학습 모드 활성화\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.view(images.size(0), -1).to(device)  # Flatten\n",
    "        labels = labels.float().unsqueeze(1).to(device)  # [32] → [32,1]\n",
    "\n",
    "        optimizer.zero_grad()              # grad 초기화\n",
    "        outputs = model(images)            # forward\n",
    "        loss = criterion(outputs, labels)  # loss 계산\n",
    "        loss.backward()                    # backward\n",
    "        optimizer.step()                   # update model param\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        preds = (outputs >= 0.5).float()   # sigmod → 0 or 1\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2846ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3-2. 학습 진행하는 함수 (검증)\n",
    "# -------------------------------\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.view(images.size(0), -1).to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. 테스트 진행 함수\n",
    "# -------------------------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()  # 평가 모드\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.view(images.size(0), -1).to(device)  # Flatten\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 5. 학습 함수를 통해 학습 \n",
    "# -------------------------------\n",
    "\n",
    "# 저장용 리스트\n",
    "lr_train_accs, lr_val_accs = [], []\n",
    "lr_train_losses, lr_val_losses = [], []\n",
    "\n",
    "dnn_train_accs, dnn_val_accs = [], []\n",
    "dnn_train_losses, dnn_val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "model1 = LogisticModel(input_dim).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model1, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(model1, val_loader, criterion)\n",
    "\n",
    "    lr_train_losses.append(train_loss)\n",
    "    lr_val_losses.append(val_loss)\n",
    "    lr_train_accs.append(train_acc)\n",
    "    lr_val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"[LR][Epoch {epoch+1}] Train Acc: {train_acc:.2f}, Train Loss: {train_loss:.2f}\")\n",
    "    print(f\"[LR][Epoch {epoch+1}] Val Acc: {val_acc:.2f}, Val Loss: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca5b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "model2 = DeepNN(input_dim).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(model2, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(model2, val_loader, criterion)\n",
    "\n",
    "    dnn_train_losses.append(train_loss)\n",
    "    dnn_val_losses.append(val_loss)\n",
    "    dnn_train_accs.append(train_acc)\n",
    "    dnn_val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"[DNN][Epoch {epoch+1}] Train Acc: {train_acc:.2f}, Train Loss: {train_loss:.2f}\")\n",
    "    print(f\"[DNN][Epoch {epoch+1}] Val Acc: {val_acc:.2f}, Val Loss: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 6. 테스트를 통해 정확도 도출\n",
    "# -------------------------------\n",
    "\n",
    "# LR\n",
    "lr_test_acc = evaluate(model1, test_loader)\n",
    "print(f\"[LR] Test Acc: {lr_test_acc:.2f}\")\n",
    "\n",
    "# DNN\n",
    "dnn_test_acc = evaluate(model2, test_loader)\n",
    "print(f\"[DNN] Test Acc: {dnn_test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93647db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 7-1. 시각화 (Flow Graph)\n",
    "# -------------------------------\n",
    "\n",
    "epochs_range = range(1, epochs + 1)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 1. Train Loss: LR vs DNN\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, lr_train_losses, label='LR', linestyle='-')\n",
    "plt.plot(epochs_range, dnn_train_losses, label='DNN', linestyle='-')\n",
    "plt.title('Train Loss (LR vs DNN)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 2. Val Loss: LR vs DNN\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, lr_val_losses, label='LR', linestyle='-')\n",
    "plt.plot(epochs_range, dnn_val_losses, label='DNN', linestyle='-')\n",
    "plt.title('Val Loss (LR vs DNN)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 3. Train Accuracy: LR vs DNN\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs_range, lr_train_accs, label='LR', linestyle='-')\n",
    "plt.plot(epochs_range, dnn_train_accs, label='DNN', linestyle='-')\n",
    "plt.title('Train Accuracy (LR vs DNN)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 4. Val Accuracy: LR vs DNN\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs_range, lr_val_accs, label='LR', linestyle='-')\n",
    "plt.plot(epochs_range, dnn_val_accs, label='DNN', linestyle='-')\n",
    "plt.title('Val Accuracy (LR vs DNN)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0eb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 7-2. 시각화 (Bar Plot)\n",
    "# -------------------------------\n",
    "\n",
    "model_names = [\"LR\", \"DNN\"]\n",
    "train_accs = [lr_train_accs[-1], dnn_train_accs[-1]]\n",
    "val_accs = [lr_val_accs[-1], dnn_val_accs[-1]]\n",
    "test_accs = [lr_test_acc, dnn_test_acc]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "bar_width = 0.25\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(x - bar_width, train_accs, width=bar_width, label=\"Train\")\n",
    "plt.bar(x, val_accs, width=bar_width, label=\"Val\")\n",
    "plt.bar(x + bar_width, test_accs, width=bar_width, label=\"Test\")\n",
    "\n",
    "plt.xticks(x, model_names)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.title(\"Chest X-ray Binary Classfication\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
